{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'comment_text': [\"Toxic comment\"] * 10 + [\"Clean comment\"] * 90,\n",
    "    'toxic': [1] * 10 + [0] * 90,\n",
    "    'severe_toxic': [1] * 5 + [0] * 95,\n",
    "    'obscene': [1] * 3 + [0] * 97,\n",
    "    'threat': [1] * 2 + [0] * 98,\n",
    "    'insult': [1] * 3 + [0] * 97,\n",
    "    'identity_hate': [1] * 5 + [0] * 95\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to split and combine datasets\n",
    "def split_and_combine(df, label_column, train_ratio=0.8):\n",
    "    # Separate positive and negative cases\n",
    "    pos_df = df[df[label_column] == 1]\n",
    "    neg_df = df[df[label_column] == 0]\n",
    "    \n",
    "    # Split positive cases\n",
    "    pos_train_df, pos_val_df = train_test_split(pos_df, test_size=1-train_ratio, stratify=pos_df[label_column])\n",
    "    \n",
    "    # Split negative cases\n",
    "    neg_train_df, neg_val_df = train_test_split(neg_df, test_size=1-train_ratio, stratify=neg_df[label_column])\n",
    "    \n",
    "    # Combine the datasets\n",
    "    train_df = pd.concat([pos_train_df, neg_train_df])\n",
    "    val_df = pd.concat([pos_val_df, neg_val_df])\n",
    "    \n",
    "    # Shuffle the combined datasets\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return train_df, val_df\n",
    "\n",
    "# Split datasets for each label\n",
    "train_df, val_df = df.copy(), df.copy()  # Start with the full dataset\n",
    "for label in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n",
    "    train_df, val_df = split_and_combine(df, label)\n",
    "\n",
    "# # Convert to lists\n",
    "# texts_train = train_df['comment_text'].tolist()\n",
    "# labels_train = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "# texts_val = val_df['comment_text'].tolist()\n",
    "# labels_val = val_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text     Clean commentClean commentToxic commentClean c...\n",
       "toxic                                                            9\n",
       "severe_toxic                                                     4\n",
       "obscene                                                          3\n",
       "threat                                                           2\n",
       "insult                                                           3\n",
       "identity_hate                                                    4\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text     Clean commentClean commentClean commentClean c...\n",
       "toxic                                                            1\n",
       "severe_toxic                                                     1\n",
       "obscene                                                          0\n",
       "threat                                                           0\n",
       "insult                                                           0\n",
       "identity_hate                                                    1\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Gintares_Projektai\\Toxic-Comment-Classification\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\User\\Desktop\\Gintares_Projektai\\Toxic-Comment-Classification\\venv\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad15a033b1e04f3582053da2b0063956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20984\\2154201256.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6928, 'grad_norm': 1.4815338850021362, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addf61bdc4bb4b2fbfc9a94c1ee8187e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6879714131355286, 'eval_runtime': 0.133, 'eval_samples_per_second': 150.344, 'eval_steps_per_second': 22.552, 'epoch': 1.0}\n",
      "{'loss': 0.6833, 'grad_norm': 1.7670224905014038, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3667235cc11840cf9f851accc6c165f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6771639585494995, 'eval_runtime': 0.131, 'eval_samples_per_second': 152.638, 'eval_steps_per_second': 22.896, 'epoch': 2.0}\n",
      "{'loss': 0.6692, 'grad_norm': 1.9891972541809082, 'learning_rate': 3e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20984\\2154201256.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbc087fe5a244ac95e388c327a982a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6555161476135254, 'eval_runtime': 0.135, 'eval_samples_per_second': 148.115, 'eval_steps_per_second': 22.217, 'epoch': 3.0}\n",
      "{'train_runtime': 8.7732, 'train_samples_per_second': 27.356, 'train_steps_per_second': 3.42, 'train_loss': 0.6817727247873943, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=0.6817727247873943, metrics={'train_runtime': 8.7732, 'train_samples_per_second': 27.356, 'train_steps_per_second': 3.42, 'total_flos': 15787230289920.0, 'train_loss': 0.6817727247873943, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example DataFrame (replace this with your actual DataFrame)\n",
    "data = {\n",
    "    'comment_text': [\"Toxic comment\"] * 10 + [\"Clean comment\"] * 90,\n",
    "    'toxic': [1] * 10 + [0] * 90,\n",
    "    'severe_toxic': [1] * 5 + [0] * 95,\n",
    "    'obscene': [1] * 3 + [0] * 97,\n",
    "    'threat': [1] * 2 + [0] * 98,\n",
    "    'insult': [1] * 3 + [0] * 97,\n",
    "    'identity_hate': [1] * 5 + [0] * 95\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate toxic samples and non-toxic samples\n",
    "toxic_df = df[df['toxic'] == 1]\n",
    "non_toxic_df = df[df['toxic'] == 0]\n",
    "\n",
    "# Calculate sizes\n",
    "toxic_train_size = int(0.1 * len(df))  # 10% of the whole dataset\n",
    "non_toxic_train_size = int(0.9 * len(df))  # The rest for non-toxic\n",
    "\n",
    "# Split toxic and non-toxic data into training and validation sets\n",
    "toxic_train_df, toxic_val_df = train_test_split(toxic_df, test_size=0.2, stratify=toxic_df['toxic'])\n",
    "non_toxic_train_df, non_toxic_val_df = train_test_split(non_toxic_df, test_size=0.2, stratify=non_toxic_df['toxic'])\n",
    "\n",
    "# Combine the data\n",
    "train_df = pd.concat([toxic_train_df, non_toxic_train_df])\n",
    "val_df = pd.concat([toxic_val_df, non_toxic_val_df])\n",
    "\n",
    "# Shuffle the datasets\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Convert to lists\n",
    "texts_train = train_df['comment_text'].tolist()\n",
    "labels_train = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "texts_val = val_df['comment_text'].tolist()\n",
    "labels_val = val_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n",
    "# Define the dataset class\n",
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "        item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=6)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = ToxicCommentDataset(texts_train, labels_train, tokenizer, max_len=128)\n",
    "val_dataset = ToxicCommentDataset(texts_val, labels_val, tokenizer, max_len=128)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset  # Provide the eval_dataset here\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Gintares_Projektai\\Toxic-Comment-Classification\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22daf9e8ddfb47f5a569f9f18dc64c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20984\\3019409088.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12610dc60e64467a2f8b5ed97a0e7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.675223708152771, 'eval_runtime': 0.0845, 'eval_samples_per_second': 11.839, 'eval_steps_per_second': 11.839, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20984\\3019409088.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080984056c9046fc9311f3a25de8c259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6751617193222046, 'eval_runtime': 0.067, 'eval_samples_per_second': 14.922, 'eval_steps_per_second': 14.922, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20984\\3019409088.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20984\\3019409088.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc93980f9154a31b56ec54edbf40972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6750385165214539, 'eval_runtime': 0.019, 'eval_samples_per_second': 52.62, 'eval_steps_per_second': 52.62, 'epoch': 3.0}\n",
      "{'train_runtime': 8.4746, 'train_samples_per_second': 0.708, 'train_steps_per_second': 0.354, 'train_loss': 0.6808248360951742, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.6808248360951742, metrics={'train_runtime': 8.4746, 'train_samples_per_second': 0.708, 'train_steps_per_second': 0.354, 'total_flos': 394680757248.0, 'train_loss': 0.6808248360951742, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "# Example DataFrame (replace this with your actual DataFrame)\n",
    "data = {\n",
    "    'comment_text': [\"This is a toxic comment\", \"This is a clean comment\"],\n",
    "    'toxic': [1, 0],\n",
    "    'severe_toxic': [0, 0],\n",
    "    'obscene': [0, 0],\n",
    "    'threat': [0, 0],\n",
    "    'insult': [0, 0],\n",
    "    'identity_hate': [0, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the features and labels\n",
    "texts = df['comment_text'].tolist()\n",
    "labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n",
    "# Define the dataset class\n",
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "        item = {key: torch.tensor(val.squeeze()) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=6)\n",
    "\n",
    "dataset = ToxicCommentDataset(texts, labels, tokenizer, max_len=128)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory for model checkpoints\n",
    "    num_train_epochs=3,              # Number of epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",           # Evaluate every epoch (updated argument)\n",
    "    save_strategy=\"epoch\"            # Save checkpoint every epoch\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import TextVectorization\n",
    "# import tensorflow as tf\n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# transformers\n",
    "# from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "# from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from help_tool import help_tool\n",
    "\n",
    "# Setting graph parameters\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = help_tool.csv_download(\n",
    "    r'Archive\\clean_data.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metallica fan reverted werent vandalisms closure gas voted new york dolls fac please dont remove template talk page since im retired</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww matches background colour im seemingly stuck thanks talk utc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>cant make real suggestions improvement wondered section statistics later subsection types accidents think references may need tidying exact format ie date format etc later noone else first preferences formatting style references want please let know appears backlog articles review guess may delay reviewer turns listed relevant form eg wikipediagoodarticlenominationstransport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141935</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>second time asking view completely contradicts coverage reliable sources anyone care feel cant even give consistent argument opening supposed mention significant aspects significant ones</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141936</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141937</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>spitzer umm theres actual article prostitution ring crunch captain</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141938</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>looks like actually put speedy first version deleted look</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141939</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>really dont think understand came idea bad right away kind community goes bad ideas go away instead helping rewrite</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141940 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0       0000997932d777bf   \n",
       "1       000103f0d9cfb60f   \n",
       "2       000113f07ec002fd   \n",
       "3       0001b41b1c6bb37e   \n",
       "4       0001d958c54c6e35   \n",
       "...                  ...   \n",
       "141935  ffe987279560d7ff   \n",
       "141936  ffea4adeee384e90   \n",
       "141937  ffee36eab5c267c9   \n",
       "141938  fff125370e4aaaf3   \n",
       "141939  fff46fc426af1f9a   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                     comment_text  \\\n",
       "0                                                                                                                                                                                                                   explanation edits made username hardcore metallica fan reverted werent vandalisms closure gas voted new york dolls fac please dont remove template talk page since im retired   \n",
       "1                                                                                                                                                                                                                                                                                                                               daww matches background colour im seemingly stuck thanks talk utc   \n",
       "2                                                                                                                                                                                                                                                hey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info   \n",
       "3       cant make real suggestions improvement wondered section statistics later subsection types accidents think references may need tidying exact format ie date format etc later noone else first preferences formatting style references want please let know appears backlog articles review guess may delay reviewer turns listed relevant form eg wikipediagoodarticlenominationstransport   \n",
       "4                                                                                                                                                                                                                                                                                                                                                             sir hero chance remember page thats   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                           ...   \n",
       "141935                                                                                                                                                                                                 second time asking view completely contradicts coverage reliable sources anyone care feel cant even give consistent argument opening supposed mention significant aspects significant ones   \n",
       "141936                                                                                                                                                                                                                                                                                                                                                       ashamed horrible thing put talk page   \n",
       "141937                                                                                                                                                                                                                                                                                                                         spitzer umm theres actual article prostitution ring crunch captain   \n",
       "141938                                                                                                                                                                                                                                                                                                                                  looks like actually put speedy first version deleted look   \n",
       "141939                                                                                                                                                                                                                                                                        really dont think understand came idea bad right away kind community goes bad ideas go away instead helping rewrite   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "141935      0             0        0       0       0              0  \n",
       "141936      0             0        0       0       0              0  \n",
       "141937      0             0        0       0       0              0  \n",
       "141938      0             0        0       0       0              0  \n",
       "141939      0             0        0       0       0              0  \n",
       "\n",
       "[141940 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clean_data.drop(columns=['id', 'comment_text']).columns\n",
    "X = clean_data.drop(columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            14210\n",
       "severe_toxic      1413\n",
       "obscene           7853\n",
       "threat             440\n",
       "insult            7383\n",
       "identity_hate     1290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (141940, 8), (141940, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set: {clean_data.shape}, {clean_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (85164, 2), (85164, 2)\n",
      "Validation set: (28388, 2), (28388, 2)\n",
      "Test set: (28388, 2), (28388, 2)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to binary format using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_binary = mlb.fit_transform(clean_data[labels].values)\n",
    "\n",
    "# Split data into train, validate, and test sets with stratification\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_binary, test_size=0.4, random_state=42, stratify=y_binary)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Print the shape of the splits\n",
    "print(f'Training set: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation set: {X_val.shape}, {y_val.shape}')\n",
    "print(f'Test set: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=help_tool.model_dataset_distribution(clean_data, X_train, X_val, X_test), hue='Dataset', y='Proc', x='Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=('id'), inplace=True)\n",
    "X_val.drop(columns=('id'), inplace=True)\n",
    "X_test.drop(columns=('id'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = help_tool.csv_download(\n",
    "#     r'Archive\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = train[train['id'].isin(X_val['id'])]['comment_text']\n",
    "# X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = train[train['id'].isin(X_test['id'])]['comment_text']\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = clean_data.drop(columns=['id', 'comment_text']).columns\n",
    "\n",
    "# # Convert labels to one-hot encoding\n",
    "# y = clean_data[labels].values\n",
    "#y = to_categorical(clean_data[labels].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If X_train is a pandas Series or DataFrame column, convert it to a list\n",
    "X_train = X_train['comment_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "['one opinion says born cuba position says information right want balance say find balance arguing skipping information write wikipage humanist tolerant respect opinions others totally alone opinion book indicates born cuba sources weak way aruge act makes suspicious emotional personal interest attacking de zayas please leave personal conflicts outside wiki thanks mp', 'comment bad faith nomination truly believe nonnotable artists nonnotable band dont meet single point set forth wpmusic reference verified feel free add ill publicly change opinion additionally pages created bands webmaster', 'redirect talkgdels incompleteness theoremsarchive']\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))  # Should be list\n",
    "print(type(X_train[0]))  # Should be str\n",
    "print(X_train[:3])  # Check the first few elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_inputs = tokenizer(X_train, \n",
    "#                            padding=True, \n",
    "#                            truncation=True, \n",
    "#                            max_length=76, \n",
    "#                            return_tensors='pt',  # Return PyTorch tensors\n",
    "#                            return_attention_mask=True)\n",
    "\n",
    "# # Extract the token IDs and attention masks\n",
    "# input_ids = encoded_inputs['input_ids']\n",
    "# attention_masks = encoded_inputs['attention_mask']\n",
    "\n",
    "# print(\"Token IDs:\", input_ids)\n",
    "# print(\"Attention Masks:\", attention_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        ...,\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_masks = encoded_inputs['attention_mask']\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x24fa7451010>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Adapt a Transformer Model for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning message you're seeing is normal when you load a pre-trained model like RoBERTa and adapt it for a specific downstream task, such as sequence classification. This happens because the classification head (the part of the model that makes predictions) is not pre-trainedâ€”it needs to be initialized and trained on your specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(X_train, \n",
    "                           padding=True, \n",
    "                           truncation=True, \n",
    "                           max_length=76, \n",
    "                           return_tensors='pt',  # Return PyTorch tensors\n",
    "                           return_attention_mask=True)\n",
    "\n",
    "# Extract the token IDs and attention masks\n",
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_masks = encoded_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to tensor\n",
    "labels_tensor = torch.tensor(y_train)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory for model checkpoints\n",
    "    num_train_epochs=3,              # Number of epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",           # Evaluate every epoch (updated argument)\n",
    "    save_strategy=\"epoch\"            # Save checkpoint every epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # The pre-trained model with new head\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=dataset,               # The training dataset\n",
    "    # You can add eval_dataset here if you have validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of transformers.utils.import_utils failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 319, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to DummyObject object\n",
      "]\n",
      "[autoreload of torch.overrides failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\overrides.py\", line 1661, in <module>\n",
      "    has_torch_function = _add_docstr(\n",
      "                         ^^^^^^^^^^^^\n",
      "RuntimeError: function '_has_torch_function' already has a docstring\n",
      "]\n",
      "[autoreload of torch.utils.dlpack failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\utils\\dlpack.py\", line 24, in <module>\n",
      "    torch._C._add_docstr(to_dlpack, r\"\"\"to_dlpack(tensor) -> PyCapsule\n",
      "RuntimeError: function '_to_dlpack' already has a docstring\n",
      "]\n",
      "[autoreload of torch._tensor failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\_tensor.py\", line 82, in <module>\n",
      "    class Tensor(torch._C.TensorBase):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\_tensor.py\", line 659, in Tensor\n",
      "    detach = _C._add_docstr(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "RuntimeError: method 'detach' already has a docstring\n",
      "]\n",
      "[autoreload of torch.storage failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 319, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _LegacyStorageMeta object\n",
      "]\n",
      "[autoreload of torch.utils._pytree failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 305, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: _register_pytree_node() requires a code object with 0 free vars, not 2538325671940\n",
      "]\n",
      "[autoreload of torch.cuda.memory failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\cuda\\memory.py\", line 20, in <module>\n",
      "    from . import (\n",
      "ImportError: cannot import name '_get_amdsmi_device_index' from 'torch.cuda' (c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\cuda\\__init__.py)\n",
      "]\n",
      "[autoreload of torch.cuda.amp.autocast_mode failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py\", line 11, in <module>\n",
      "    class autocast(torch.amp.autocast_mode.autocast):\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.amp' has no attribute 'autocast_mode'\n",
      "]\n",
      "[autoreload of torch.cuda.amp.grad_scaler failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 345, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 305, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 1 free vars, not 2538325671940\n",
      "]\n",
      "[autoreload of torch.cuda failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 267, in <module>\n",
      "    OutOfMemoryError = torch._C.OutOfMemoryError\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch._C' has no attribute 'OutOfMemoryError'\n",
      "]\n",
      "[autoreload of torch.sparse failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\sparse\\__init__.py\", line 42, in <module>\n",
      "    addmm = _add_docstr(_sparse._sparse_addmm, r\"\"\"\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: function '_sparse_addmm' already has a docstring\n",
      "]\n",
      "[autoreload of torch._prims_common failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 305, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: check() requires a code object with 0 free vars, not 2538325671940\n",
      "]\n",
      "[autoreload of torch.nn.parameter failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 319, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _ParameterMeta object\n",
      "]\n",
      "[autoreload of torch._torch_docs failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\_torch_docs.py\", line 192, in <module>\n",
      "    add_docstr(\n",
      "RuntimeError: function 'abs' already has a docstring\n",
      "]\n",
      "c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py:366: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  setattr(self, k, v)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine all the necessary text processing functions into a single function\n",
    "# def process_text(text):\n",
    "#     # Define the regex pattern to remove dates and IP addresses\n",
    "#     combined_pattern = (\n",
    "#         r'\\b(?:\\d{1,2}, \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"31, 19 July 2006\"\n",
    "#         r'\\d{1,2} \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"31 19 July 2006\"\n",
    "#         r'\\d{1,2} [A-Za-z]{3,10}, \\d{4}|'  # \"31 July, 2006\"\n",
    "#         r'\\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"31 July 2006\"\n",
    "#         r'\\d{1,2}, [A-Za-z]{3,10} \\d{4}, \\d{1,2}:\\d{2}|'  # \"31, July 2006, 18:47\"\n",
    "#         r'\\d{1,2} [A-Za-z]{3,10} \\d{4}, \\d{1,2}:\\d{2}|'  # \"31 July 2006, 18:47\"\n",
    "#         r'\\d{1,2} [A-Za-z]{3,10} \\d{4} \\d{1,2}:\\d{2}|'  # \"31 July 2006 18:47\"\n",
    "#         r'\\d{1,2}:\\d{2}, [A-Za-z]{3,10} \\d{1,2}, \\d{4}|'  # \"18:47, July 31, 2006\"\n",
    "#         r'\\d{1,2}:\\d{2}, \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"18:47, 31 July 2006\"\n",
    "#         r'\\d{1,2}:\\d{2} \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"18:47 31 July 2006\"\n",
    "#         r'\\d{1,2} [A-Za-z]{3,10} \\d{1,2}:\\d{2}|'  # \"26 July 17:03 UTC\"\n",
    "#         r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b'  # IP address\n",
    "#         r')\\b'\n",
    "#     )\n",
    "\n",
    "#     # Remove dates and IP addresses\n",
    "#     text = re.sub(combined_pattern, '', text)\n",
    "\n",
    "#     # Replace specific prefixes\n",
    "#     text = re.sub(r'Wikipedia:|WP:|Category:|disambiguation|otheruses', '', text)\n",
    "\n",
    "#     # Replace filenames (implement your function or use a placeholder here)\n",
    "#     text = help_tool.replace_filenames(text)\n",
    "\n",
    "#     # Clean the text (implement your function or use a placeholder here)\n",
    "#     text = help_tool.clean_text(text)\n",
    "\n",
    "#     # Remove stopwords (implement your function or use a placeholder here)\n",
    "#     text = help_tool.remove_stopwords(text)\n",
    "\n",
    "#     # Remove non-ASCII characters (implement your function or use a placeholder here)\n",
    "#     text = help_tool.remove_non_ascii(text)\n",
    "\n",
    "#     return text.strip()\n",
    "\n",
    "# # Apply the combined text processing function\n",
    "# clean_data['comment_text'] = clean_data['comment_text'].apply(process_text)\n",
    "\n",
    "# # Remove empty strings and duplicates\n",
    "# clean_data = clean_data[clean_data['comment_text'] != '']\n",
    "# clean_data = clean_data.drop_duplicates()\n",
    "\n",
    "# # Filter out rows containing 'Navbox'\n",
    "# clean_data = clean_data[~clean_data['comment_text'].str.contains(\"Navbox\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['comment_text'] = train['comment_text'].apply(help_tool.replace_url_with_domain)\n",
    "\n",
    "# combined_pattern = (\n",
    "#     r'\\b(?:\\d{1,2}, \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"31, 19 July 2006\"\n",
    "#     r'\\d{1,2} \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"31 19 July 2006\"\n",
    "#     r'\\d{1,2} [A-Za-z]{3,10}, \\d{4}|'  # \"31 July, 2006\"\n",
    "#     r'\\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"31 July 2006\"\n",
    "#     r'\\d{1,2}, [A-Za-z]{3,10} \\d{4}, \\d{1,2}:\\d{2}|'  # \"31, July 2006, 18:47\"\n",
    "#     r'\\d{1,2} [A-Za-z]{3,10} \\d{4}, \\d{1,2}:\\d{2}|'  # \"31 July 2006, 18:47\"\n",
    "#     r'\\d{1,2} [A-Za-z]{3,10} \\d{4} \\d{1,2}:\\d{2}|'  # \"31 July 2006 18:47\"\n",
    "#     r'\\d{1,2}:\\d{2}, [A-Za-z]{3,10} \\d{1,2}, \\d{4}|'  # \"18:47, July 31, 2006\"\n",
    "#     r'\\d{1,2}:\\d{2}, \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"18:47, 31 July 2006\"\n",
    "#     r'\\d{1,2}:\\d{2} \\d{1,2} [A-Za-z]{3,10} \\d{4}|'  # \"18:47 31 July 2006\"\n",
    "#     r'\\d{1,2} [A-Za-z]{3,10} \\d{1,2}:\\d{2}|'  # \"26 July 17:03 UTC\"\n",
    "#     r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b'  # IP address\n",
    "#     r')\\b'\n",
    "# )\n",
    "\n",
    "\n",
    "# # Remove the date pattern from the 'comment_text' column\n",
    "# train['comment_text'] = train['comment_text'].str.replace(combined_pattern, '', regex=True).str.strip()\n",
    "\n",
    "# train['comment_text'] = train['comment_text'].replace(\n",
    "#     {'Wikipedia:': '', 'WP:': '', 'Category:': '', 'disambiguation': '', 'otheruses': ''\n",
    "#      })\n",
    "\n",
    "# train = train[~ train['comment_text'].str.contains(\"Navbox\")]\n",
    "\n",
    "# train['comment_text'] = train['comment_text'].apply(help_tool.replace_filenames)\n",
    "\n",
    "# train['comment_text'] = train['comment_text'].apply(help_tool.clean_text)\n",
    "\n",
    "# train['comment_text'] = train['comment_text'].apply(help_tool.remove_stopwords)\n",
    "\n",
    "# train['comment_text'] = train['comment_text'].apply(help_tool.remove_non_ascii)\n",
    "\n",
    "# train = train[train['comment_text'] != '']\n",
    "\n",
    "# train = train[~train['comment_text'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data Preparation\n",
    "Dataset: Typically, the dataset for this task includes text comments labeled with multiple classes indicating different types of toxicity (e.g., toxic, severe_toxic, obscene, threat, insult, identity_hate).\n",
    "Preprocessing: This includes tokenizing the text, padding sequences, and converting labels to a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen = 18\n",
    "batch_size = 64\n",
    "padding_token = \"<pad>\"\n",
    "auto = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecotorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111449\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "X_train['comment_text'].str.lower().str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.211061  0.        0.       ...  0.        0.        0.      ]\n",
      " [27.763826  0.        0.       ...  0.        0.        0.      ]\n",
      " [16.658297  0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [16.658297  0.        0.       ...  0.        0.        0.      ]\n",
      " [11.105531  0.        0.       ...  0.        0.        0.      ]\n",
      " [16.658297  0.        0.       ...  0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "# Limit vocabulary size to a reasonable number, e.g., 10,000\n",
    "max_vocabulary_size = 2000  # Adjust as needed\n",
    "\n",
    "# Define the TextVectorization layer\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocabulary_size, \n",
    "    ngrams=1,  # Use ngrams=1 for unigrams if still facing issues\n",
    "    output_mode=\"tf_idf\"\n",
    ")\n",
    "\n",
    "# Adapt the TextVectorization layer to the training data\n",
    "text_vectorizer.adapt(X_train['comment_text'])\n",
    "\n",
    "# Optional: Define a function to truncate sequences to the max length\n",
    "def truncate_sequences(sequences, maxlen):\n",
    "    return tf.strings.substr(sequences, 0, maxlen)\n",
    "\n",
    "# Apply truncation before vectorization\n",
    "truncated_texts = X_train['comment_text'].apply(lambda x: ' '.join(x.split()[:max_seqlen]))\n",
    "\n",
    "# Transform the truncated comment texts into vectorized form\n",
    "vectorized_texts = text_vectorizer(truncated_texts)\n",
    "\n",
    "# If you need the result as a NumPy array\n",
    "vectorized_texts_np = vectorized_texts.numpy()\n",
    "\n",
    "# Display the vectorized output\n",
    "print(vectorized_texts_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=20000)  # use the top 20,000 words\n",
    "tokenizer.fit_on_texts(X_train['comment_text'])\n",
    "\n",
    "# Convert texts to sequences\n",
    "X = tokenizer.texts_to_sequences(X_train['comment_text'])\n",
    "X = pad_sequences(X, maxlen=76)  # pad to a max length of 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  145,   16, 4788],\n",
       "       [   0,    0,    0, ...,  205, 1504, 8066],\n",
       "       [   0,    0,    0, ...,    0,    0,  186],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    7, 1045,  614],\n",
       "       [   0,    0,    0, ..., 1980,   67, 5289],\n",
       "       [   0,    0,    0, ...,  616,  676,  331]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y = clean_data[labels].values\n",
    "y = to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(5, activation='sigmoid')  # 5 output neurons for 5 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85164, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85164, 2)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 2), output.shape=(None, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Gintares_Projektai\\Mushrooms_classification\\model_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:675\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[1;32m--> 675\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    676\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    677\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    678\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m         )\n\u001b[0;32m    681\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[0;32m    682\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    683\u001b[0m )\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 2), output.shape=(None, 5)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Creation\n",
    "You can use an embedding layer followed by a series of LSTM, GRU, or CNN layers, with a final dense layer using a softmax activation function to output probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "The model is trained on the prepared data, typically with a validation split to monitor the performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
    "lookup.adapt(terms)\n",
    "vocab = lookup.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(512, activation=\"relu\"),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "        ]  # More on why \"sigmoid\" has been used here in a moment.\n",
    "    )\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lookup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 3\u001b[0m shallow_mlp_model \u001b[38;5;241m=\u001b[39m \u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m shallow_mlp_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      5\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m history \u001b[38;5;241m=\u001b[39m shallow_mlp_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     X_train, y_train, X_val, y_val, epochs\u001b[38;5;241m=\u001b[39mepochs\n\u001b[0;32m     10\u001b[0m )\n",
      "Cell \u001b[1;32mIn[183], line 6\u001b[0m, in \u001b[0;36mmake_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_model\u001b[39m():\n\u001b[0;32m      2\u001b[0m     shallow_mlp_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      3\u001b[0m         [\n\u001b[0;32m      4\u001b[0m             layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m             layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m----> 6\u001b[0m             layers\u001b[38;5;241m.\u001b[39mDense(\u001b[43mlookup\u001b[49m\u001b[38;5;241m.\u001b[39mvocabulary_size(), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m         ]  \u001b[38;5;66;03m# More on why \"sigmoid\" has been used here in a moment.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shallow_mlp_model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lookup' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"binary_accuracy\"]\n",
    ")\n",
    "\n",
    "history = shallow_mlp_model.fit(\n",
    "    X_train, y_train, X_val, y_val, epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"binary_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "After training, evaluate the model on the test data to determine its accuracy, precision, recall, F1-score, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the validation set\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# To get more detailed evaluation metrics like precision, recall, and F1-score:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "y_val_classes = y_val.argmax(axis=-1)\n",
    "\n",
    "print(classification_report(y_val_classes, y_pred_classes, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning and Optimization\n",
    "You might want to fine-tune the model by adjusting hyperparameters like the learning rate, batch size, or network architecture.\n",
    "Consider techniques like dropout, regularization, and batch normalization to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and Loading the Model\n",
    "Once the model is trained, you can save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('toxic_comment_model.h5')\n",
    "\n",
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('toxic_comment_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on New Data\n",
    "To make predictions on new comments, preprocess them in the same way as the training data and then use the trained model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comments = [\"This is an example comment.\", \"Another comment that could be toxic.\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_comments)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=100)\n",
    "\n",
    "predictions = model.predict(new_padded)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
